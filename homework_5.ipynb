{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style=\"margin-top: 50px; font-size: 33px; text-align: center\"> Homework 5 - Visit the Wikipedia hyperlinks graph! </h1>\n",
    "    <br>\n",
    "    <div style=\"font-weight:200; font-size: 20px; padding-bottom: 15px; width: 100%; text-align: center;\">\n",
    "        <right>Maria Luisa Croci, Livia Lilli, Pavan Kumar Alikana</right>\n",
    "        <br>\n",
    "    </div>\n",
    "    <hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from heapq import *\n",
    "import numpy as np\n",
    "import collections\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first requests, we can use 2 different approaches:\n",
    "\n",
    "* We can start from the file building a dictionary that describe our graph; we do it because we will need this dictionary for the request 2;\n",
    "\n",
    "* Or, better, we can use an easy command <b>nx.info</b>, to get all the informations we need.\n",
    "\n",
    "So let's see!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start downloading <a href=\"https://drive.google.com/file/d/1ghPJ4g6XMCUDFQ2JPqAVveLyytG8gBfL/view\">Wikicat hyperlink graph</a> . \n",
    "\n",
    "It is a reduced version of the one we can find on SNAP. \n",
    "\n",
    "Every row is an <b>edge</b>. The two elements of each row are the <b>nodes</b>, in particular the first is the <b> source</b>, the second represents the <b>destination</b>.\n",
    "\n",
    "So, our first goal is open and read the file with python, and split each line with the new line charachter.\n",
    "Then we take all the <i>source nodes</i> for each row, and we put them as keys into our <b>graph</b> dictionary. The values will be all the correspondent destination nodes.\n",
    "\n",
    "But we have not done! Infact our scope is to analyze the graph, in particular discovering the following informations:\n",
    "\n",
    "* If it is direct or not;\n",
    "\n",
    "* The number of nodes;\n",
    "\n",
    "* The number of edges;\n",
    "\n",
    "* The average node degree. Is the graph dense?\n",
    "\n",
    "To do this we want that our dictionary has as keys <u>all the nodes</u>, sources and destinations, and for now we have just the first ones. So we add as new keys all the nodes that are just destinations, putting as values empty lists.\n",
    "\n",
    "\n",
    "Now we have the dictionary with all the nodes of our graph as keys, and as values there are all the eventual destinations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = open('wiki-topcats-reduced.txt','r') \n",
    "all_rows = F.read().split('\\n')\n",
    "\n",
    "graph = {}\n",
    "for row in all_rows:\n",
    "    row = row.split(\"\\t\")\n",
    "    if row[0] not in graph:\n",
    "        try:\n",
    "            graph[row[0]] = [row[1]]\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        graph[row[0]].append(row[1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for l in graph.values():\n",
    "    lista+= l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in lista:\n",
    "    if node not in graph:\n",
    "        graph[node] = []\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what can we say?\n",
    "\n",
    "* We are in a case of <b>page ranking</b>. So for definition we have nodes representing sources and destinations, with edges with a particular direction. In other words, our graph has a set of edges which are <i>ordered pairs</i> of nodes, and for the graph theory we have a <b>directed graph</b>.\n",
    "\n",
    "\n",
    "* The number of nodes is <u>461193</u>. It's just the number of keys of our dictionary.\n",
    "\n",
    "\n",
    "* The number of edges is <u>2645247</u> and it's computed looking at all the lenghts of the <b>adjacency list</b>.\n",
    "\n",
    "\n",
    "* In graph theory, the <b>degree</b> (or <i>valency</i>) of a vertex of a graph is the number of edges incident to the vertex. We need the <b>average node degree</b>, so we compute the ratio between number of edges and number of nodes. It results <u>5.735661642739591</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = list(graph.keys())\n",
    "n_nodes = len(V)\n",
    "n_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = 0\n",
    "for l in graph.values():\n",
    "    n_edges += len(l)\n",
    "n_edges    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avarage node degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_degree = n_edges/n_nodes\n",
    "avg_degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, since we need the average in and out degree because our graph is directed, we could use an easy command nx.info as follow, in order to obtain the basic informations.\n",
    "\n",
    "First import the graph from the reduced file of the list of edges indicating with nx.DiGraph that what we want is an oriented graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_edgelist(\"wiki-topcats-reduced.txt\", delimiter=\"\\t\", create_using=nx.DiGraph())\n",
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the graph dense?**\n",
    "\n",
    "With the following formula $D=\\frac{E}{N(N-1)}$ we obtain a value that could go from 0 up to 1. It measure the probability that any pairs of vertex is connected, so technically if the density is close to 1 the number of edges is close to the maximal number of edges, viceversa if the density is close to 0 we have a graph with only few edges (called sparse graph).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.density(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could expect, according to the number of nodes and edges that we already know, the density is very low, so it means that our graph is sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start creating a dictionary called <b>categories</b> where for every category taken from <i>wiki-topcats-categories.txt</i> file, we have the list of all its articles. But attention! We must take into account all the categories that has a number of articles greater than <b>3500</b>. So we filter our dictionary considering the categories with more that 3500 articles. Another, we take just the articles that are the result of the intersection between the set of articles of the category and the articles of our <b>graph</b>; in other words, we don't consider those nodes that are in our graph but not in our categories!\n",
    "\n",
    "\n",
    "We create also a dictionary called <b>inv_dic</b> that shows for every node (article), a set of all the categories associated. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = open('wiki-topcats-categories.txt','r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for line in C.readlines():\n",
    "    l = line.split(' ')\n",
    "    cat = l[0].replace(\"Category:\",\"\").replace(\";\", \"\")\n",
    "    art = l[1:]\n",
    "    art[-1] = art[-1].replace(\"\\n\",\"\")\n",
    "    if len(art) >= 3500:\n",
    "        categories[cat]= set(art).intersection(set(V))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set = categories.values()\n",
    "all_nodes = []\n",
    "for s in all_set:\n",
    "    all_nodes += s\n",
    "inv_dic = {}\n",
    "for node in all_nodes:\n",
    "    for cat in categories:\n",
    "        if node in categories[cat] and node not in inv_dic:\n",
    "            inv_dic[node] = [cat]\n",
    "        elif node in categories[cat] and node in inv_dic and cat not in inv_dic[node]:\n",
    "            inv_dic[node].append(cat)\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Ranking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scope now is, to take in input a category $C_0 = \\{article_1, article_2, \\dots \\}$. Then we want to rank all of the nodes according to the following criterion:\n",
    "\n",
    "Obtain a <b>block-ranking</b>, where the blocks are represented by the categories.\n",
    "The first category of the rank, $C_0$, always corresponds to the input category. The order of the remaining categories is given by: $$distance(C_0, C_1) = median(ShortestPath(C_0, C_i))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we do that? At first we create the functions we need.\n",
    "\n",
    "Our input category is 'Year_of_birth_unknown' for convention because the one with the smaller number of nodes.\n",
    "\n",
    "* The first function we write is the <b> ShortestPath</b> which takes in input a node (of the input category) and our graph. It computes the distances, using the visit in amplitude of the graph. For this we apply the <b><i>BFS</i></b> algorithm, that consists in searching graph data structures. It starts at the <i>tree root</i> (or some arbitrary node of a graph called <i>search key</i>), and at first it explores all of the neighbor nodes at the present depth prior, moving on to the nodes at the next depth level. The gif below shows this concept.\n",
    "\n",
    "So the SorthestPath function creates a dictionary where the keys are the nodes (including the input node) and their value are the distances from the node of the input category. \n",
    "\n",
    "The distance from the node of the input category to itself is written as zero. The others are started as -1, and then eventually incremented.\n",
    "\n",
    "\n",
    "* Now it's the turn of <b>createDistancesDict</b> function, which take 4 elements as input: the input category, the graph, the <i>categories</i> dictionary and finally the <i>inv_dic</i>. In easy words, it applies the ShortestPath function to every node of the input cateogory creating a dictionary where each key is one of these nodes, and the value is a dictionary where for every other node of the graph there is the distance from the starting node of C0.\n",
    "\n",
    "\n",
    "* Now we create the <b>dictDistanceCi</b> dictionary, where we wanna show for each category a list of all the distances of the correspondent nodes from the nodes of the input category. Of course we don't need the distances among the nodes of the input cateogory, so we don't consider them.\n",
    "\n",
    "\n",
    "* A the end of our process, we compute for each category (taken from the precedent dictionary) the <b>median</b> of the correspondent distances. Then we add in an Ordered Dictionary called <b>rank</b> each category with its value of median. So we obtain our <b>BLOCK RANKING</b>.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Breadth-First-Search-Algorithm.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_category = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShortestPath(c0, graph):\n",
    "    queue = []\n",
    "    queue.append(c0)\n",
    "    \n",
    "    distanceDict = dict()\n",
    "    for node in graph:\n",
    "        distanceDict[node] = -1\n",
    "    distanceDict[c0] = 0\n",
    "\n",
    "    while queue:\n",
    "        vertex = queue.pop(0)\n",
    "        for i in graph[vertex]:\n",
    "            if distanceDict[i] == -1:\n",
    "                queue.append(i)\n",
    "                distanceDict[i] = distanceDict[vertex] + 1\n",
    "    return distanceDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMedian(lista):\n",
    "    lung = len(lista)\n",
    "    #ordinata = sorted(lista)\n",
    "    ordinata = lista\n",
    "    if(lung % 2 != 0):\n",
    "        return ordinata[lung/2]\n",
    "    else:\n",
    "        return (ordinata[lung/2]) + (ordinata[lung/2 + 1]) /2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pickle\n",
    "\n",
    "def createDistancesDict(c0, graph, dizionarioCatNodi, listNode):\n",
    "    \n",
    "    #listNode è un dizionario <articolo, [categorie]>\n",
    "    \n",
    "    #Prendo come categoria 0 la lista di nodi della categoria 0\n",
    "    Category0 = dizionarioCatNodi[c0]\n",
    "    \n",
    "    #Dizionario dove per ogni chiave(articolo in C0) c'è un dizionatio (nodo, distanza) con la distanza verso tutti gli altri nodi \n",
    "    dictDistances = dict()\n",
    "    \n",
    "    for node in tqdm(Category0):\n",
    "        try:\n",
    "            dictDistances[node] = ShortestPath(node, graph)\n",
    "        except Exception as e: print(e)\n",
    "    \n",
    "    with open(\"distance_dict.p\", 'wb') as handle:\n",
    "        pickle.dump(dictDistances, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createDistancesDict(input_category, graph, categories, inv_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"distance_dict.p\", 'rb') as handle:\n",
    "    dist_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictDistanceCi = dict()\n",
    "#inizializzo le distanze da C0 per ogni categoria ad una lista vuota\n",
    "for cat in categories:\n",
    "    dictDistanceCi[cat] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for every cat the distances of its nodes from nodes of C0\n",
    "for node in dist_dict:\n",
    "    for node2 in dist_dict[node]:\n",
    "        for cat in inv_dic[node2]:\n",
    "            if cat != inv_dic[node]:\n",
    "                dictDistanceCi[cat].append(dist_dict[node][node2])\n",
    "\n",
    "with open(\"dictDistanceCi.p\", 'ab') as handle:\n",
    "    pickle.dump(dictDistanceCi, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictDistanceCi.p\", 'rb') as handle:\n",
    "    dictDistanceCi = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = OrderedDict()\n",
    "for cat in tqdm(dictDistanceCi):\n",
    "    distance = np.median(dictDistanceCi[cat])\n",
    "    rank[cat] = distance\n",
    "\n",
    "rank['Year_of_birth_unknown'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_rank = {}\n",
    "for tupla in rank:\n",
    "    block_rank[tupla[0]] = tupla[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in block_rank:\n",
    "    if block_rank[el] == -1.0:\n",
    "        block_rank[el] = 10000.0\n",
    "block_rank = sorted(block_rank.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained the Ordered Dictionary <b>rank</b> we notice that there are some categories with median equal to -1. This means that these categories are not reachable from the input category and so the values of distance among their nodes and the input category ones didn't change its initial values -1 associated during the inizialization in the BFS. For this reason we give to them a big value, for example 10000, so that in the block rank they will stay at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting nodes of category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we obtain the <i>block ranking vector</i>, we want to sort the nodes in each category. The way we should sort them is the following..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We have to compute the subgraph induced by $C_0$. Then, for each node, we compute the sum of the weigths of the <b>in-edges</b>. The nodes will be ordered by this score.\n",
    " The following image explains how to do it for each step.\n",
    " \n",
    " In other words, we have to consider a category, and for that category we must compute for each node the number of in-edges, but considering just those that have the source of the same category! For example, in the first image, the B node of the category \"0\" has got 2 in-edges, but only one is from a node of the same category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/CriMenghini/ADM-2018/master/Homework_5/imgs/algorithm.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this scope we have created a function called <b>in_edges</b> that implements our idea of sorting, given as input a category. \n",
    "\n",
    "So we apply this function for each category saving the correspondent dictionary on a file <i>pickle</i>, naming it as <i>\"cat_i.p\"</i> where i is the index of the i-category. To control the correspondence index-category, we create a dictionary where for each category we have its index; we call it <b>indexing</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our <i>in_edge()</i> function do exactly? \n",
    "\n",
    "Well, we can see that for a node <i>n1</i> of the choosen category, it starts a contator and for every node <i>n2</i> of our graph checks two important things:\n",
    "\n",
    "* if there is an edge from <i>n2</i> to <i>n1</i>;\n",
    "\n",
    "* if <i>n2</i>, the source node, is in the same category of <i>n1</i>;\n",
    "\n",
    "If these 2 points are respected, then it increments the contator of <i>n1</i>. \n",
    "\n",
    "At the end, it saves in a dictionary each node n1 and its contator, or in other words, the number of its in-edges.\n",
    "But it's not finished! We want to sort the nodes in the dictionary in base of their values, so we just do it. Now the output is ready!\n",
    "\n",
    "\n",
    "We have reported as examples some of our  dictionaries saved on pickle. In particular you can see that for \"the category 7\"  (that in our block ranking correponds to the <b>Category0</b>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cat = list(categories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_edges(cat, graph):\n",
    "    n_cat = categories[cat]\n",
    "    d = {}\n",
    "    for n1 in tqdm(n_cat):\n",
    "        count = 0\n",
    "        for n2 in graph:\n",
    "            if n1 in graph[n2] and n2 in n_cat:\n",
    "                count += 1\n",
    "        d[n1] = count\n",
    "    d = sorted(d.items(), key=lambda x: x[1])\n",
    "    return d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_cat)):\n",
    "    dd = in_edges(all_cat[i], graph)\n",
    "    \n",
    "    #pickle.dump(dd, open( \"cat\"+str(i)+\".p\", \"wb\" ) )\n",
    "    with open(\"cat\"+str(i)+\".p\", 'wb') as handle:\n",
    "        pickle.dump(dd, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing = {}\n",
    "for i in range(len(all_cat)):\n",
    "    indexing[all_cat[i]] = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there is the indexing dictionary, that occurs to us to find the in_edge dictionary of a particular category, starting from its index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, as promised, we have the dictionary for the category 0 of our block ranking, or in other words, the category7 of our indexing.\n",
    "\n",
    "For convention we print just a portion of it, in particular a part where we can see the moment where the score changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cat\"+str(7)+\".p\", 'rb') as handle:\n",
    "    dd7 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dd7[1600:1700])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://scalar.usc.edu/works/querying-social-media-with-nodexl/media/Network_theoryarticlenetworkonWikipedia1point5deg.jpg\" height=\"200\" width=\"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
